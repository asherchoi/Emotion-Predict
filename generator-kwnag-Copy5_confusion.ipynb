{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from cnnmodel import model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import os, random, cv2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFileList(myDir):\n",
    "    format = ('.tiff','.jpg','.png','.PNG')\n",
    "    fileList = []\n",
    "    print(os.walk(myDir, topdown=False))\n",
    "    for root, dirs, files in os.walk(myDir, topdown=False):\n",
    "        \n",
    "        for name in files:\n",
    "            if name.endswith(format):\n",
    "                fullName = os.path.join(root, name)\n",
    "                fileList.append(fullName)\n",
    "    return fileList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x7f8899318db0>\n"
     ]
    }
   ],
   "source": [
    "classes={0:'angry', 1:'fear', 2:'happy', 3:'neutral', 4:'sad', 5:'surprise'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "#train_dir에 적용\n",
    "#e.g. case sad\n",
    "#path 읽어 = [(1,227,227)만들기 |  파싱하여 label 얻기] \n",
    "\n",
    "#train_x.append(q)\n",
    "'''\n",
    "z = load_img(path = './data/train/sad/KA.SA2.34.tiff', grayscale=True, target_size=(227,227),\n",
    "    interpolation='nearest')\n",
    "q=np.asarray(z).astype('float32')\n",
    "print(np.asarray([q]).shape)\n",
    "q = np.asarray([q])\n",
    "'''\n",
    "\n",
    "fileList = []\n",
    "fileList = createFileList('./data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "(2022, 1, 227, 227)\n",
      "(2022, 6)\n"
     ]
    }
   ],
   "source": [
    "train_x = [] #(10000,1,227,227) (1,227,227)에 대해 append\n",
    "train_y = [] #(10000, 6) \n",
    "\n",
    "for x in fileList:\n",
    "    z = load_img(path =x, grayscale=True, target_size=(227,227),\n",
    "    interpolation='nearest')\n",
    "    q=np.asarray(z).astype('float32')\n",
    "    q = np.asarray([q])\n",
    "    train_x.append(q)\n",
    "    \n",
    "    t = -1\n",
    "    for y in classes.items():\n",
    "        if y[1] in x:\n",
    "            print(y[0])\n",
    "            t = y[0]\n",
    "        \n",
    "    train_y.append(to_categorical(t, 6))\n",
    "\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "print(train_x.shape)   \n",
    "print(train_y.shape)   \n",
    "\n",
    "train_len = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x7f8899318db0>\n",
      "(252, 1, 227, 227)\n",
      "(252, 6)\n"
     ]
    }
   ],
   "source": [
    "#이상  train_x/ train_y 구성 끝\n",
    "\n",
    "#val_x/ val_y 도 일단 똑같이 구성\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "\n",
    "\n",
    "fileList = createFileList('./data/valid')\n",
    "\n",
    "\n",
    "\n",
    "for x in fileList:\n",
    "    z = load_img(path =x, grayscale=True, target_size=(227,227),\n",
    "    interpolation='nearest')\n",
    "    q=np.asarray(z).astype('float32')\n",
    "    q = np.asarray([q])\n",
    "    val_x.append(q)\n",
    "    \n",
    "    t = -1\n",
    "    for y in classes.items():\n",
    "        if y[1] in x:\n",
    "            t = y[0]\n",
    "        \n",
    "    val_y.append(to_categorical(t, 6))\n",
    "\n",
    "val_x = np.asarray(val_x)\n",
    "val_y = np.asarray(val_y)\n",
    "print(val_x.shape)   \n",
    "print(val_y.shape)   \n",
    "\n",
    "val_len = train_x.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_datagen = ImageDataGenerator(\\n    featurewise_center=True,\\n    featurewise_std_normalization=True,\\n    #rescale=1./255,\\n    rotation_range=10,\\n    shear_range=0.1,\\n    fill_mode = 'constant',\\n    cval = 0,\\n    horizontal_flip=True)\\n\\nprint(train_x.shape)\\ntrain_x_moveaxis = np.moveaxis(train_x, 1, 3)  \\nprint(train_x_moveaxis.shape)\\ntrain_datagen.fit(train_x_moveaxis)\\n\\ntrain_x_mean = train_datagen.mean\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    shear_range=0.1,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 0,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "print(train_x.shape)\n",
    "train_x_moveaxis = np.moveaxis(train_x, 1, 3)  \n",
    "print(train_x_moveaxis.shape)\n",
    "train_datagen.fit(train_x_moveaxis)\n",
    "\n",
    "train_x_mean = train_datagen.mean\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2022, 1, 227, 227)\n",
      "(2022, 227, 227, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:511: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    #samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #rescale=1./255,\n",
    "    #rotation_range=10,\n",
    "    rotation_range=25,\n",
    "    shear_range=0.17,\n",
    "    zoom_range=0.17,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,    \n",
    "    fill_mode = 'constant',\n",
    "    cval = 0,\n",
    "    horizontal_flip=True)\n",
    "    \n",
    "\n",
    "print(train_x.shape)\n",
    "train_x_moveaxis = np.moveaxis(train_x, 1, 3)\n",
    "print(train_x_moveaxis.shape)\n",
    "train_datagen.fit(train_x_moveaxis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSampleWise Normalization에 대한 확인 코드 \\n\\n#temp = train_datagen.flow(train_x_moveaxis, train_y, batch_size =3)\\na =temp.next()\\na[0][1].shape\\nprint(np.average(a[0][2]))\\nprint(np.std(a[0][2]))\\n\\n#print(a[0][0].shape)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "SampleWise Normalization에 대한 확인 코드 \n",
    "\n",
    "#temp = train_datagen.flow(train_x_moveaxis, train_y, batch_size =3)\n",
    "a =temp.next()\n",
    "a[0][1].shape\n",
    "print(np.average(a[0][2]))\n",
    "print(np.std(a[0][2]))\n",
    "\n",
    "#print(a[0][0].shape)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:511: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    #rescale=1./255, \n",
    ")\n",
    "val_x_moveaxis = np.moveaxis(val_x, 1, 3)  \n",
    "val_datagen.fit(val_x_moveaxis)\n",
    "#val_datagen.mean = x꺼 배끼끼\n",
    "#print(val_datagen.mean)\n",
    "#val_datagen.mean = train_x_mean\n",
    "#print(val_datagen.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (11, 11), input_shape=(227, 227,..., padding=\"valid\")`\n",
      "  \n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "  app.launch_new_instance()\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(2, 2), data_format=\"channels_last\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (5, 5))`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(144, (3, 3))`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3))`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 217, 217, 36)      4392      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 217, 217, 36)      144       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 217, 217, 36)      1695204   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 221, 221, 36)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 109, 109, 36)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 111, 111, 36)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 107, 107, 96)      86496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 107, 107, 96)      384       \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 107, 107, 96)      1099104   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 109, 109, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 107, 107, 144)     124560    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 107, 107, 144)     576       \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 107, 107, 144)     1648656   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 53, 53, 144)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 55, 55, 144)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 53, 53, 96)        124512    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 53, 53, 96)        384       \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 53, 53, 96)        269664    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 53, 53, 128)       110720    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 53, 53, 128)       512       \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 53, 53, 128)       359552    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 93312)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              95552512  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "p_re_lu_7 (PReLU)            (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 6150      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 102,143,386\n",
      "Trainable params: 102,138,278\n",
      "Non-trainable params: 5,108\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `ZeroPadding2D` call to the Keras 2 API: `ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `PReLU` call to the Keras 2 API: `PReLU(weights=None, alpha_initializer=\"zero\")`\n"
     ]
    }
   ],
   "source": [
    "#sequential model definition\n",
    "#model.compile\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "def model_generate():\n",
    "    img_rows, img_cols = 227, 227\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(36, 11, 11, border_mode='valid',\n",
    "                            input_shape=(img_rows, img_cols,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(2, 2), dim_ordering='tf'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5),strides=(2, 2)))\n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf')) \n",
    "    \n",
    "    model.add(Convolution2D(96, 5, 5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf')) \n",
    "    \n",
    "    model.add(Convolution2D(144, 3, 3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "     \n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf'))\n",
    "    model.add(Convolution2D(96, 3, 3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    \n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf'))\n",
    "    model.add(Convolution2D(128, 3, 3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "     \n",
    "    model.add(keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='tf'))\n",
    "    model.add(keras.layers.convolutional.AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "     \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.advanced_activations.PReLU(init='zero', weights=None))\n",
    "    model.add(Dropout(0.2))\n",
    "     \n",
    "      \n",
    "    model.add(Dense(6))\n",
    "    model.add(BatchNormalization())\n",
    "      \n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ada = Adadelta(lr=0.1, rho=0.95, epsilon=1e-08)\n",
    "    #model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=ada,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = model_generate()\n",
    "\n",
    "\n",
    "filepath='samplewise_norm_model+aug+additive+confusion_v2.hdf5'\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "759/758 [==============================] - 264s 347ms/step - loss: 1.1966 - acc: 0.5781 - val_loss: 0.8824 - val_acc: 0.6905\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69048, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 2/60\n",
      "759/758 [==============================] - 228s 300ms/step - loss: 0.8650 - acc: 0.7473 - val_loss: 0.7235 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69048 to 0.79762, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 3/60\n",
      "759/758 [==============================] - 228s 301ms/step - loss: 0.7419 - acc: 0.8075 - val_loss: 0.6681 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.6839 - acc: 0.8268 - val_loss: 0.5948 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.79762 to 0.84127, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 5/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.6204 - acc: 0.8550 - val_loss: 0.6112 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.5691 - acc: 0.8759 - val_loss: 0.7418 - val_acc: 0.7659\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.5323 - acc: 0.8860 - val_loss: 0.5588 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.84127 to 0.84127, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 8/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.5051 - acc: 0.8961 - val_loss: 0.5770 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.4709 - acc: 0.9045 - val_loss: 0.5506 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.84127 to 0.85317, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 10/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.4401 - acc: 0.9141 - val_loss: 0.5155 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.85317 to 0.87302, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 11/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.4193 - acc: 0.9178 - val_loss: 0.4192 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87302 to 0.90476, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 12/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.4022 - acc: 0.9222 - val_loss: 0.5144 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.3769 - acc: 0.9289 - val_loss: 0.5650 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.3597 - acc: 0.9332 - val_loss: 0.4362 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.3450 - acc: 0.9342 - val_loss: 0.4053 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.90476 to 0.92063, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 16/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.3267 - acc: 0.9398 - val_loss: 0.4422 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.3126 - acc: 0.9447 - val_loss: 0.4244 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.2979 - acc: 0.9463 - val_loss: 0.3659 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.2857 - acc: 0.9511 - val_loss: 0.4040 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.2783 - acc: 0.9510 - val_loss: 0.3681 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.2655 - acc: 0.9524 - val_loss: 0.3461 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.2510 - acc: 0.9575 - val_loss: 0.4044 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.2477 - acc: 0.9563 - val_loss: 0.3316 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00023: val_acc did not improve\n",
      "Epoch 24/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.2321 - acc: 0.9622 - val_loss: 0.3477 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.2231 - acc: 0.9608 - val_loss: 0.3272 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.2130 - acc: 0.9647 - val_loss: 0.3622 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.2146 - acc: 0.9616 - val_loss: 0.3859 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1994 - acc: 0.9682 - val_loss: 0.4123 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1922 - acc: 0.9680 - val_loss: 0.3337 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1931 - acc: 0.9669 - val_loss: 0.3732 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1837 - acc: 0.9706 - val_loss: 0.3673 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1795 - acc: 0.9699 - val_loss: 0.3177 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1726 - acc: 0.9711 - val_loss: 0.3178 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00033: val_acc did not improve\n",
      "Epoch 34/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1683 - acc: 0.9725 - val_loss: 0.3316 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00034: val_acc did not improve\n",
      "Epoch 35/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1676 - acc: 0.9724 - val_loss: 0.3398 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1595 - acc: 0.9747 - val_loss: 0.4506 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1551 - acc: 0.9748 - val_loss: 0.4948 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1485 - acc: 0.9766 - val_loss: 0.2745 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.92063 to 0.92460, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 39/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1406 - acc: 0.9797 - val_loss: 0.3459 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1456 - acc: 0.9777 - val_loss: 0.3417 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1394 - acc: 0.9769 - val_loss: 0.3594 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1359 - acc: 0.9785 - val_loss: 0.3067 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1300 - acc: 0.9795 - val_loss: 0.3279 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1300 - acc: 0.9790 - val_loss: 0.3815 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1254 - acc: 0.9800 - val_loss: 0.2879 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1229 - acc: 0.9805 - val_loss: 0.3155 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1182 - acc: 0.9813 - val_loss: 0.3457 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1160 - acc: 0.9837 - val_loss: 0.3079 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.1160 - acc: 0.9817 - val_loss: 0.3036 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1135 - acc: 0.9819 - val_loss: 0.2858 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.92460 to 0.93254, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 51/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1148 - acc: 0.9820 - val_loss: 0.2966 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00051: val_acc did not improve\n",
      "Epoch 52/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1041 - acc: 0.9847 - val_loss: 0.2872 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.93254 to 0.93651, saving model to samplewise_norm_model+aug+additive+confusion_v2.hdf5\n",
      "Epoch 53/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.1044 - acc: 0.9841 - val_loss: 0.2824 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00053: val_acc did not improve\n",
      "Epoch 54/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.0997 - acc: 0.9857 - val_loss: 0.2785 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00054: val_acc did not improve\n",
      "Epoch 55/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.0988 - acc: 0.9847 - val_loss: 0.2747 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00055: val_acc did not improve\n",
      "Epoch 56/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.0986 - acc: 0.9852 - val_loss: 0.2683 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00056: val_acc did not improve\n",
      "Epoch 57/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.0974 - acc: 0.9850 - val_loss: 0.2714 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00057: val_acc did not improve\n",
      "Epoch 58/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.0944 - acc: 0.9845 - val_loss: 0.2857 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00058: val_acc did not improve\n",
      "Epoch 59/60\n",
      "759/758 [==============================] - 229s 301ms/step - loss: 0.0926 - acc: 0.9852 - val_loss: 0.3381 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00059: val_acc did not improve\n",
      "Epoch 60/60\n",
      "759/758 [==============================] - 229s 302ms/step - loss: 0.0883 - acc: 0.9861 - val_loss: 0.2859 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00060: val_acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88992bdc88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(train_x_moveaxis, train_y, batch_size =batch_size),\n",
    "                    #steps_per_epoch = train_len/batch_size*12,\n",
    "                    steps_per_epoch = train_len/batch_size*12,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = val_datagen.flow(val_x_moveaxis,val_y,batch_size = batch_size),\n",
    "                    callbacks = [checkpointer])\n",
    "\n",
    "#l = train_datagen.flow(train_x_moveaxis, train_y, batch_size =batch_size)\n",
    "\n",
    "#next(l)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={0:'angry', 1:'fear', 2:'happy', 3:'neutral', 4:'sad', 5:'surprise'}\n",
    "#vd = val_datagen.flow(val_x_moveaxis,val_y,batch_size = 1)\n",
    "#sample = vd.next()\n",
    "#sample_x,sample_y = sample\n",
    "#print(sam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total data # * steps for epochs / batchsize  ==  172 \n",
    "Therefore, 172 * 32(batchsize) == A total data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x7f881a114e60>\n",
      "(252, 1, 227, 227)\n",
      "(252, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(252, 227, 227, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from keras.models import load_model\n",
    "#model_1 = keras.load(\"samplewise_norm_model+aug+additive+confusion.hdf5\")\n",
    "#model_1 = load_model(\"samplewise_norm_model+aug+additive+confusion.hdf5\")\n",
    "test_x = [] #(10000,1,227,227) (1,227,227)에 대해 append\n",
    "test_y = [] #(10000, 6) \n",
    "\n",
    "\n",
    "fileList = []\n",
    "fileList = createFileList('./data/test')\n",
    "\n",
    "\n",
    "\n",
    "for x in fileList:\n",
    "    z = load_img(path =x, grayscale=True, target_size=(227,227),\n",
    "    interpolation='nearest')\n",
    "    q=np.asarray(z).astype('float32')\n",
    "    q = np.asarray([q])\n",
    "    test_x.append(q)\n",
    "     \n",
    "    t = -1\n",
    "    for y in classes.items():\n",
    "        if y[1] in x:\n",
    "            t = y[0]\n",
    "        \n",
    "    test_y.append(to_categorical(t, 6))\n",
    "\n",
    "    \n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)\n",
    "print(test_x.shape)   \n",
    "print(test_y.shape)   \n",
    "test_x_moveaxis = np.moveaxis(test_x, 1, 3)  \n",
    "test_x_moveaxis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py:511: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    samplewise_std_normalization=True,\n",
    "    #rescale=1./255, \n",
    ")\n",
    "#print(\"0hi\")\n",
    "#print(test_datagen.mean)\n",
    "test_datagen.fit(test_x_moveaxis[:])\n",
    "#print(test_datagen.mean)\n",
    "#test_datagen.mean = [[[0]]]\n",
    "#print(valid_datagen.mean)\n",
    "\"\"\"\n",
    "TEST CODE\n",
    "e1 = model.predict_generator(valid_datagen.flow(valid_x_moveaxis,valid_y,batch_size = 1,shuffle= False))\n",
    "print(valid_datagen.mean)\n",
    "print([np.argmax(pre) for pre in e1])\n",
    "#print(val_x_moveaxis[0])\n",
    "#print(val_y)\n",
    "print(e1)\n",
    "print([np.argmax(x) for x in valid_y])\n",
    "\n",
    "\"\"\"\n",
    "#classes={0:'angry', 1:'fear', 2:'happy', 3:'neutral', 4:'sad', 5:'surprise'}\n",
    "gener = test_datagen.flow(test_x_moveaxis, test_y, batch_size = 1,shuffle= False)\n",
    "pred_batch = model.predict_generator(test_datagen.flow(test_x_moveaxis,test_y,batch_size = 1,shuffle= False))\n",
    "#e1은 (batchsize, 6) e1[0] == (0.12233, 0.123142, 0.12312, 0.11, 0.01, 0.34342)\n",
    "#batchsize 를 아싸리 test 모든 set 크기로 해놓고 200, 6 \n",
    "#y_pred = [np.argmax(x) for x in pred_batch] \n",
    "#y_true = [np.argmax(x) for x in valid_y]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    if ymap != None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "    plt.savefig(filename)\n",
    "classes={0:'angry', 1:'fear', 2:'happy', 3:'neutral', 4:'sad', 5:'surprise'}\n",
    "ymap = ['angry', 'fear', 'happy','neutral', 'sad','surprise']\n",
    "labels = [0,1,2,3,4,5]\n",
    "y_pred = [np.argmax(x) for x in pred_batch] \n",
    "y_true = [np.argmax(x) for x in test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f878c2ac908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = \"./conjusion2.jpg\"\n",
    "cm_analysis(y_true, y_pred,filename,labels, ymap=classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
